{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "use_ramdon_split = False\n",
    "use_dataparallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 详细GPU诊断 ===\n",
      "PyTorch版本: 2.7.1+cu118\n",
      "正在检查CUDA可用性...\n",
      "CUDA可用: True\n",
      "CUDA设备数量: 1\n",
      "当前CUDA设备: 0\n",
      "GPU 0: NVIDIA GeForce RTX 2080\n",
      "  总内存: 8.0 GB\n",
      "  计算能力: 7.5\n",
      "  多处理器数量: 46\n",
      "\n",
      "CUDA_VISIBLE_DEVICES: 0\n",
      "\n",
      "=== 使用nvidia-smi检查系统GPU ===\n",
      "nvidia-smi 输出:\n",
      "Wed Oct  8 17:19:53 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 471.41       Driver Version: 471.41       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:2D:00.0 Off |                  N/A |\n",
      "| 40%   41C    P8     6W / 225W |   1454MiB /  8192MiB |     13%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2388    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      2452    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      3508    C+G   ...updated_web\\WXWorkWeb.exe    N/A      |\n",
      "|    0   N/A  N/A      5208    C+G   ... iCUE 4 Software\\iCUE.exe    N/A      |\n",
      "|    0   N/A  N/A      6652    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      7016    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A      8956    C+G   ...x64__adky2gkssdxte\\XD.exe    N/A      |\n",
      "|    0   N/A  N/A     12120    C+G   ...rograms\\Cursor\\Cursor.exe    N/A      |\n",
      "|    0   N/A  N/A     12560    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     12912    C+G   ...ative Cloud UI Helper.exe    N/A      |\n",
      "|    0   N/A  N/A     15196    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     15560    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     16152    C+G   ...t\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A     16392    C+G   ...n64\\EpicGamesLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A     16504    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     17580    C+G   ...lugins\\FlutterPlugins.exe    N/A      |\n",
      "|    0   N/A  N/A     20724    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     23188    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     23560    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     23684    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     25168    C+G   ...7pnf6hceqser\\snipaste.exe    N/A      |\n",
      "|    0   N/A  N/A     30000    C+G   ...\\Autodesk AdSSO\\AdSSO.exe    N/A      |\n",
      "|    0   N/A  N/A     31220    C+G   ...cher\\AdskAccessUIHost.exe    N/A      |\n",
      "|    0   N/A  N/A     32256    C+G   ...s\\Win64\\EpicWebHelper.exe    N/A      |\n",
      "|    0   N/A  N/A     33576    C+G   ...x64\\electron-qq-login.exe    N/A      |\n",
      "|    0   N/A  N/A     36660    C+G   ...537.57\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     36708    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     38900    C+G   ...3d8bbwe\\CalculatorApp.exe    N/A      |\n",
      "|    0   N/A  N/A     39152    C+G   ...4__htrsf667h5kn2\\AWCC.exe    N/A      |\n",
      "|    0   N/A  N/A     40780    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     41124    C+G   ...6.500.638\\XnnExternal.exe    N/A      |\n",
      "|    0   N/A  N/A     41276    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     41800    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     43480    C+G   ...d\\runtime\\WeChatAppEx.exe    N/A      |\n",
      "|    0   N/A  N/A     47708    C+G   Insufficient Permissions        N/A      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "# 详细GPU诊断\n",
    "import torch\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# 添加路径以导入utils模块\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "print(\"=== 详细GPU诊断 ===\")\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "\n",
    "# 安全地检查CUDA可用性\n",
    "print(\"正在检查CUDA可用性...\")\n",
    "try:\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA可用: {cuda_available}\")\n",
    "    \n",
    "    if cuda_available:\n",
    "        try:\n",
    "            device_count = torch.cuda.device_count()\n",
    "            print(f\"CUDA设备数量: {device_count}\")\n",
    "            \n",
    "            if device_count > 0:\n",
    "                print(f\"当前CUDA设备: {torch.cuda.current_device()}\")\n",
    "                for i in range(device_count):\n",
    "                    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "                    props = torch.cuda.get_device_properties(i)\n",
    "                    print(f\"  总内存: {props.total_memory / 1024**3:.1f} GB\")\n",
    "                    print(f\"  计算能力: {props.major}.{props.minor}\")\n",
    "                    print(f\"  多处理器数量: {props.multi_processor_count}\")\n",
    "            else:\n",
    "                print(\"没有检测到CUDA设备\")\n",
    "        except Exception as e:\n",
    "            print(f\"获取CUDA设备信息时出错: {e}\")\n",
    "    else:\n",
    "        print(\"CUDA不可用\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"检查CUDA时出错: {e}\")\n",
    "    print(\"可能的原因:\")\n",
    "    print(\"1. PyTorch安装有问题\")\n",
    "    print(\"2. CUDA驱动未安装\")\n",
    "    print(\"3. PyTorch版本与CUDA不兼容\")\n",
    "\n",
    "# 检查环境变量\n",
    "print(f\"\\nCUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', '未设置')}\")\n",
    "\n",
    "# 尝试使用nvidia-smi检查\n",
    "print(\"\\n=== 使用nvidia-smi检查系统GPU ===\")\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=10)\n",
    "    if result.returncode == 0:\n",
    "        print(\"nvidia-smi 输出:\")\n",
    "        print(result.stdout)\n",
    "    else:\n",
    "        print(f\"nvidia-smi 错误: {result.stderr}\")\n",
    "except Exception as e:\n",
    "    print(f\"nvidia-smi 执行失败: {e}\")\n",
    "    print(\"可能的原因:\")\n",
    "    print(\"1. nvidia-smi 未安装\")\n",
    "    print(\"2. NVIDIA驱动未安装\")\n",
    "    print(\"3. 没有NVIDIA GPU\")\n",
    "\n",
    "print(\"==================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PyTorch安装检查 ===\n",
      "✓ PyTorch已安装，版本: 2.7.1+cu118\n",
      "✓ PyTorch支持CUDA\n",
      "✓ torch.version 模块存在\n",
      "✓ CUDA版本: 11.8\n",
      "==================\n",
      "=== 测试GPU工具函数 ===\n",
      "query_gpu() 返回结果:\n",
      "  GPU 0: 0, NVIDIA GeForce RTX 2080, 6747 MiB\n",
      "select_gpu() 返回结果: [0]\n",
      "将使用GPU: [0]\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "# PyTorch安装检查\n",
    "print(\"=== PyTorch安装检查 ===\")\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"✓ PyTorch已安装，版本: {torch.__version__}\")\n",
    "    \n",
    "    # 检查是否有CUDA支持\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"✓ PyTorch支持CUDA\")\n",
    "    else:\n",
    "        print(\"✗ PyTorch不支持CUDA或CUDA不可用\")\n",
    "        \n",
    "    # 检查torch.version是否存在（在PyTorch 2.7.1中可能不存在）\n",
    "    if hasattr(torch, 'version'):\n",
    "        print(\"✓ torch.version 模块存在\")\n",
    "        if hasattr(torch.version, 'cuda'):\n",
    "            print(f\"✓ CUDA版本: {torch.version.cuda}\")\n",
    "        else:\n",
    "            print(\"✗ torch.version.cuda 不存在\")\n",
    "    else:\n",
    "        print(\"ℹ torch.version 模块不存在（这在PyTorch 2.7.1中是正常的）\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"✗ PyTorch未安装\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ PyTorch检查失败: {e}\")\n",
    "\n",
    "print(\"==================\")\n",
    "\n",
    "# 测试GPU工具函数\n",
    "print(\"=== 测试GPU工具函数 ===\")\n",
    "try:\n",
    "    # 添加路径以导入utils模块\n",
    "    import sys\n",
    "    import os\n",
    "    sys.path.insert(0, '..')\n",
    "    \n",
    "    from utils.gpu_tools import query_gpu, select_gpu\n",
    "    \n",
    "    # 查询GPU信息\n",
    "    gpu_info = query_gpu()\n",
    "    print(f\"query_gpu() 返回结果:\")\n",
    "    for i, line in enumerate(gpu_info):\n",
    "        print(f\"  GPU {i}: {line.strip()}\")\n",
    "    \n",
    "    # 选择GPU\n",
    "    selected_gpus = select_gpu(gpu_info)\n",
    "    print(f\"select_gpu() 返回结果: {selected_gpus}\")\n",
    "    \n",
    "    if selected_gpus:\n",
    "        print(f\"将使用GPU: {selected_gpus}\")\n",
    "    else:\n",
    "        print(\"没有选择到可用的GPU\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"GPU工具函数测试失败: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"==================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPU状态检查 ===\n",
      "CUDA可用: True\n",
      "GPU数量: 1\n",
      "GPU 0: NVIDIA GeForce RTX 2080\n",
      "  内存: 8.0 GB\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "# GPU状态检查\n",
    "print(\"=== GPU状态检查 ===\")\n",
    "print(f\"CUDA可用: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU数量: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  内存: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"没有可用的CUDA设备\")\n",
    "print(\"==================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "if use_gpu:\n",
    "    from utils.gpu_tools import *\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join([ str(obj) for obj in select_gpu(query_gpu())])\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 新的图像尺寸参数\n",
    "# 78根K线 * 3像素宽 = 234，加6个空列 + padding4*2 = 248\n",
    "IMAGE_WIDTH = 248\n",
    "IMAGE_HEIGHT = 248\n",
    "NUM_CHANNELS = 1  # 只使用R通道（K线数据）\n",
    "NUM_KBARS = 78  # 昨日72根5分钟K线 + 今日开盘6根K线  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "\n",
    "here we choose 1993-2001 data as our training(include validation) data, the remaining will be used in testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 加载训练数据 ===\n",
      "数据目录: ../notebooks/training_data\n",
      "找到年份: [2020]\n",
      "加载 2020 年数据...\n",
      "  图像形状: (15120, 248, 248, 3)\n",
      "  标签形状: (15120, 18)\n",
      "\n",
      "数据加载成功！\n",
      "总图像数: 15120\n",
      "总标签数: 15120\n",
      "\n",
      "数据加载成功！\n",
      "图像形状: (15120, 248, 248, 3)\n",
      "标签形状: (15120, 18)\n",
      "标签列: ['year', 'day_pair_idx', 'time_str', 'atr', '10k_4atr', '10k_2atr', '10k_1atr', '10k_0atr', '10k_-1atr', '10k_-2atr', '10k_-4atr', '5k_3atr', '5k_2atr', '5k_1atr', '5k_0atr', '5k_-1atr', '5k_-2atr', '5k_-3atr']\n",
      "\n",
      "年份分布:\n",
      "  2020: 15120 个样本\n",
      "\n",
      "标签统计:\n",
      "  10k_4atr: 1264.0/15120 (8.4%)\n",
      "  10k_2atr: 2034.0/15120 (13.5%)\n",
      "  10k_1atr: 3217.0/15120 (21.3%)\n",
      "  10k_0atr: 3318.0/15120 (21.9%)\n",
      "  10k_-1atr: 2381.0/15120 (15.7%)\n",
      "  10k_-2atr: 2144.0/15120 (14.2%)\n",
      "  10k_-4atr: 760.0/15120 (5.0%)\n",
      "  5k_3atr: 453.0/15120 (3.0%)\n",
      "  5k_2atr: 1474.0/15120 (9.7%)\n",
      "  5k_1atr: 3779.0/15120 (25.0%)\n",
      "  5k_0atr: 4535.0/15120 (30.0%)\n",
      "  5k_-1atr: 2935.0/15120 (19.4%)\n",
      "  5k_-2atr: 1211.0/15120 (8.0%)\n",
      "  5k_-3atr: 733.0/15120 (4.8%)\n",
      "\n",
      "保存前两张图像用于检查...\n",
      "  保存: sample_1_RGB.png\n",
      "    图像形状: (248, 248, 3)\n",
      "    数值范围: [0, 255]\n",
      "  保存: sample_1_R通道(K线).png\n",
      "    通道: R通道(K线)\n",
      "    数值范围: [0, 255]\n",
      "  保存: sample_1_G通道(EMA).png\n",
      "    通道: G通道(EMA)\n",
      "    数值范围: [0, 255]\n",
      "  保存: sample_1_B通道(ZIGZAG).png\n",
      "    通道: B通道(ZIGZAG)\n",
      "    数值范围: [0, 255]\n",
      "  标签信息: {'year': 2020, 'day_pair_idx': 0, 'time_str': '10-00', 'atr': 0.1513642857142843, '10k_4atr': 0.0, '10k_2atr': 0.0, '10k_1atr': 0.0, '10k_0atr': 1.0, '10k_-1atr': 0.0, '10k_-2atr': 0.0, '10k_-4atr': 0.0, '5k_3atr': 0.0, '5k_2atr': 0.0, '5k_1atr': 0.0, '5k_0atr': 1.0, '5k_-1atr': 0.0, '5k_-2atr': 0.0, '5k_-3atr': 0.0}\n",
      "\n",
      "  保存: sample_2_RGB.png\n",
      "    图像形状: (248, 248, 3)\n",
      "    数值范围: [0, 255]\n",
      "  保存: sample_2_R通道(K线).png\n",
      "    通道: R通道(K线)\n",
      "    数值范围: [0, 255]\n",
      "  保存: sample_2_G通道(EMA).png\n",
      "    通道: G通道(EMA)\n",
      "    数值范围: [0, 255]\n",
      "  保存: sample_2_B通道(ZIGZAG).png\n",
      "    通道: B通道(ZIGZAG)\n",
      "    数值范围: [0, 255]\n",
      "  标签信息: {'year': 2020, 'day_pair_idx': 0, 'time_str': '10-05', 'atr': 0.15167285714285542, '10k_4atr': 0.0, '10k_2atr': 0.0, '10k_1atr': 1.0, '10k_0atr': 0.0, '10k_-1atr': 0.0, '10k_-2atr': 0.0, '10k_-4atr': 0.0, '5k_3atr': 1.0, '5k_2atr': 0.0, '5k_1atr': 0.0, '5k_0atr': 0.0, '5k_-1atr': 0.0, '5k_-2atr': 0.0, '5k_-3atr': 0.0}\n",
      "\n",
      "调试图像已保存到: ../pic/debug_images\n"
     ]
    }
   ],
   "source": [
    "# 使用新的数据加载函数\n",
    "# 数据格式：\n",
    "# - 图像：(N, H, W, C) = (N, 248, 248, 3) - RGB格式\n",
    "# - 标签：DataFrame with multiple label columns (10k_*, 5k_*)\n",
    "\n",
    "# 设置数据目录\n",
    "data_dir = \"../notebooks/training_data\"\n",
    "\n",
    "# 直接实现数据加载函数\n",
    "def load_training_data_simple(data_dir):\n",
    "    \"\"\"\n",
    "    简单的训练数据加载函数\n",
    "    \"\"\"\n",
    "    import glob\n",
    "    \n",
    "    print(\"=== 加载训练数据 ===\")\n",
    "    print(f\"数据目录: {data_dir}\")\n",
    "    \n",
    "    # 查找所有年份的数据文件\n",
    "    image_files = glob.glob(os.path.join(data_dir, \"year_*_images.dat\"))\n",
    "    label_files = glob.glob(os.path.join(data_dir, \"year_*_labels.feather\"))\n",
    "    \n",
    "    if not image_files or not label_files:\n",
    "        print(\"错误: 没有找到数据文件！\")\n",
    "        return None, None\n",
    "    \n",
    "    # 提取年份\n",
    "    years = []\n",
    "    for file in image_files:\n",
    "        year = int(os.path.basename(file).split('_')[1])\n",
    "        years.append(year)\n",
    "    years = sorted(years)\n",
    "    \n",
    "    print(f\"找到年份: {years}\")\n",
    "    \n",
    "    images_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for year in years:\n",
    "        image_file = os.path.join(data_dir, f\"year_{year}_images.dat\")\n",
    "        label_file = os.path.join(data_dir, f\"year_{year}_labels.feather\")\n",
    "        \n",
    "        if os.path.exists(image_file) and os.path.exists(label_file):\n",
    "            print(f\"加载 {year} 年数据...\")\n",
    "            \n",
    "            # 加载图像数据\n",
    "            img_data = np.memmap(image_file, dtype=np.uint8, mode='r')\n",
    "            # 重塑为正确的形状 (N, 248, 248, 3)\n",
    "            img_data = img_data.reshape((-1, 248, 248, 3))\n",
    "            images_list.append(img_data)\n",
    "            \n",
    "            # 加载标签数据\n",
    "            labels = pd.read_feather(label_file)\n",
    "            labels_list.append(labels)\n",
    "            \n",
    "            print(f\"  图像形状: {img_data.shape}\")\n",
    "            print(f\"  标签形状: {labels.shape}\")\n",
    "        else:\n",
    "            print(f\"警告: {year} 年数据文件不完整，跳过\")\n",
    "    \n",
    "    if images_list and labels_list:\n",
    "        # 合并所有数据\n",
    "        images = np.concatenate(images_list, axis=0)\n",
    "        labels_df = pd.concat(labels_list, ignore_index=True)\n",
    "        \n",
    "        print(f\"\\n数据加载成功！\")\n",
    "        print(f\"总图像数: {images.shape[0]}\")\n",
    "        print(f\"总标签数: {len(labels_df)}\")\n",
    "        return images, labels_df\n",
    "    else:\n",
    "        print(\"错误: 没有成功加载任何数据！\")\n",
    "        return None, None\n",
    "\n",
    "# 加载训练数据\n",
    "images, label_df = load_training_data_simple(data_dir)\n",
    "\n",
    "if images is not None and label_df is not None:\n",
    "    print(f\"\\n数据加载成功！\")\n",
    "    print(f\"图像形状: {images.shape}\")\n",
    "    print(f\"标签形状: {label_df.shape}\")\n",
    "    print(f\"标签列: {label_df.columns.tolist()}\")\n",
    "    \n",
    "    # 显示年份分布\n",
    "    if 'year' in label_df.columns:\n",
    "        print(f\"\\n年份分布:\")\n",
    "        year_counts = label_df['year'].value_counts().sort_index()\n",
    "        for year, count in year_counts.items():\n",
    "            print(f\"  {year}: {count} 个样本\")\n",
    "    \n",
    "    # 显示标签统计\n",
    "    print(f\"\\n标签统计:\")\n",
    "    for col in label_df.columns:\n",
    "        if col.startswith(('10k_', '5k_')):\n",
    "            positive_count = label_df[col].sum()\n",
    "            total_count = len(label_df)\n",
    "            percentage = (positive_count / total_count) * 100 if total_count > 0 else 0\n",
    "            print(f\"  {col}: {positive_count}/{total_count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 保存前两张图像为PNG文件用于检查\n",
    "    import cv2\n",
    "    import os\n",
    "    \n",
    "    # 创建输出目录\n",
    "    debug_dir = \"../pic/debug_images\"\n",
    "    os.makedirs(debug_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n保存前两张图像用于检查...\")\n",
    "    for i in range(min(2, images.shape[0])):\n",
    "        # 获取图像数据 (H, W, C)\n",
    "        img = images[i]  # 形状: (248, 248, 3)\n",
    "        \n",
    "        # 保存RGB图像\n",
    "        filename = f\"sample_{i+1}_RGB.png\"\n",
    "        filepath = os.path.join(debug_dir, filename)\n",
    "        cv2.imwrite(filepath, img)\n",
    "        \n",
    "        print(f\"  保存: {filename}\")\n",
    "        print(f\"    图像形状: {img.shape}\")\n",
    "        print(f\"    数值范围: [{img.min()}, {img.max()}]\")\n",
    "        \n",
    "        # 分别保存每个通道\n",
    "        channel_names = ['R通道(K线)', 'G通道(EMA)', 'B通道(ZIGZAG)']\n",
    "        for channel_idx in range(3):\n",
    "            channel_img = img[:, :, channel_idx]  # 形状: (248, 248)\n",
    "            \n",
    "            filename = f\"sample_{i+1}_{channel_names[channel_idx]}.png\"\n",
    "            filepath = os.path.join(debug_dir, filename)\n",
    "            cv2.imwrite(filepath, channel_img)\n",
    "            \n",
    "            print(f\"  保存: {filename}\")\n",
    "            print(f\"    通道: {channel_names[channel_idx]}\")\n",
    "            print(f\"    数值范围: [{channel_img.min()}, {channel_img.max()}]\")\n",
    "        \n",
    "        # 打印标签信息\n",
    "        if i < len(label_df):\n",
    "            print(f\"  标签信息: {label_df.iloc[i].to_dict()}\")\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    print(f\"调试图像已保存到: {debug_dir}\")\n",
    "    \n",
    "else:\n",
    "    print(\"错误: 数据加载失败！\")\n",
    "    print(f\"请检查数据目录: {data_dir}\")\n",
    "    print(\"确保存在以下格式的文件:\")\n",
    "    print(\"  - year_YYYY_images.dat\")\n",
    "    print(\"  - year_YYYY_labels.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img, label):\n",
    "        self.img = torch.Tensor(img.copy())\n",
    "        self.label = torch.Tensor(label)\n",
    "        self.len = len(img)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.img[idx], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 创建二分类标签 ===\n",
      "找到10k标签列: ['10k_4atr', '10k_2atr', '10k_1atr', '10k_0atr', '10k_-1atr', '10k_-2atr', '10k_-4atr']\n",
      "使用标签列: ['10k_4atr', '10k_2atr', '10k_1atr']\n",
      "二分类标签统计:\n",
      "  涨（标签=1）: 6515 个样本 (43.1%)\n",
      "  跌（标签=0）: 8605 个样本 (56.9%)\n",
      "数据集初始化:\n",
      "  原始图像形状: (10584, 248, 248, 3)\n",
      "  R通道图像形状: torch.Size([10584, 1, 248, 248])\n",
      "  标签形状: torch.Size([10584])\n",
      "数据集初始化:\n",
      "  原始图像形状: (4536, 248, 248, 3)\n",
      "  R通道图像形状: torch.Size([4536, 1, 248, 248])\n",
      "  标签形状: torch.Size([4536])\n",
      "顺序分割: 训练集 10584 样本, 验证集 4536 样本\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    股票图像数据集\n",
    "    只使用R通道（K线数据）进行训练\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, img, label):\n",
    "        \"\"\"\n",
    "        参数:\n",
    "        img: numpy数组，形状为 (N, H, W, C) - RGB格式\n",
    "        label: numpy数组，形状为 (N,) 或 (N, num_classes)\n",
    "        \"\"\"\n",
    "        # 提取R通道（K线数据）\n",
    "        if len(img.shape) == 4 and img.shape[3] == 3:\n",
    "            # RGB格式，提取R通道\n",
    "            img_r = img[:, :, :, 0]  # 形状: (N, H, W)\n",
    "        elif len(img.shape) == 3:\n",
    "            # 已经是单通道\n",
    "            img_r = img\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的图像格式: {img.shape}\")\n",
    "        \n",
    "        # 添加通道维度 (N, H, W) -> (N, 1, H, W)\n",
    "        img_r = np.expand_dims(img_r, axis=1)\n",
    "        \n",
    "        # 转换为float32并归一化到[0,1]\n",
    "        self.img = torch.FloatTensor(img_r.astype(np.float32) / 255.0)\n",
    "        self.label = torch.FloatTensor(label)\n",
    "        self.len = len(img_r)\n",
    "        \n",
    "        print(f\"数据集初始化:\")\n",
    "        print(f\"  原始图像形状: {img.shape}\")\n",
    "        print(f\"  R通道图像形状: {self.img.shape}\")\n",
    "        print(f\"  标签形状: {self.label.shape}\")\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.img[idx], self.label[idx]\n",
    "# 创建二分类标签：10k_1atr及以上为涨（1），其他为跌（0）\n",
    "print(f\"\\n=== 创建二分类标签 ===\")\n",
    "\n",
    "# 获取所有10k_标签列\n",
    "label_columns = [col for col in label_df.columns if col.startswith('10k_')]\n",
    "print(f\"找到10k标签列: {label_columns}\")\n",
    "\n",
    "# 检查是否有10k_1atr及以上标签\n",
    "target_columns = [col for col in label_columns if col in ['10k_1atr', '10k_2atr', '10k_4atr']]\n",
    "\n",
    "if target_columns:\n",
    "    print(f\"使用标签列: {target_columns}\")\n",
    "    # 如果任何一个目标标签为1，则为涨（标签=1）\n",
    "    labels = (label_df[target_columns].sum(axis=1) > 0).values.astype(int)\n",
    "    print(f\"二分类标签统计:\")\n",
    "    print(f\"  涨（标签=1）: {labels.sum()} 个样本 ({labels.mean()*100:.1f}%)\")\n",
    "    print(f\"  跌（标签=0）: {(1-labels).sum()} 个样本 ({(1-labels.mean())*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"错误: 没有找到10k_1atr及以上标签列！\")\n",
    "    labels = np.zeros(len(label_df), dtype=int)\n",
    "\n",
    "# 数据集分割\n",
    "if not use_ramdon_split:\n",
    "    train_val_ratio = 0.7\n",
    "    split_idx = int(images.shape[0] * 0.7)\n",
    "    train_dataset = MyDataset(images[:split_idx], labels[:split_idx])\n",
    "    val_dataset = MyDataset(images[split_idx:], labels[split_idx:])\n",
    "    print(f\"顺序分割: 训练集 {split_idx} 样本, 验证集 {len(images)-split_idx} 样本\")\n",
    "else:\n",
    "    dataset = MyDataset(images, labels)\n",
    "    train_val_ratio = 0.7\n",
    "    train_dataset, val_dataset = random_split(dataset, \\\n",
    "        [int(dataset.len*train_val_ratio), dataset.len-int(dataset.len*train_val_ratio)], \\\n",
    "        generator=torch.Generator().manual_seed(42))\n",
    "    del dataset\n",
    "    print(f\"随机分割: 训练集 {len(train_dataset)} 样本, 验证集 {len(val_dataset)} 样本\")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split method (not random split is recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接在notebook中定义StockCNN模型类\n",
    "import torch.nn as nn\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "class StockCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    股票图像CNN模型\n",
    "    专为248x248单通道图像设计\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        # 根据248x248输入计算的全连接层输入尺寸\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(253952, 2),  # 二分类输出\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        # 输入格式: (batch_size, 1, 248, 248)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.reshape(x.size(0), -1)  # 动态计算flatten后的尺寸\n",
    "        x = self.fc1(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用StockCNN模型（专为248x248单通道图像设计）\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if use_gpu else 'cpu'\n",
    "export_onnx = True\n",
    "\n",
    "# 使用新的StockCNN模型，专为248x248单通道图像设计\n",
    "print(f\"使用StockCNN模型（专为248x248单通道图像设计）\")\n",
    "\n",
    "# 创建模型\n",
    "net = StockCNN().to(device)\n",
    "net.apply(init_weights)\n",
    "\n",
    "if export_onnx:\n",
    "    import torch.onnx\n",
    "    # 更新输入尺寸为新的格式 (batch_size, channels, height, width)\n",
    "    x = torch.randn([1, 1, IMAGE_HEIGHT, IMAGE_WIDTH]).to(device)\n",
    "    torch.onnx.export(net,               # model being run\n",
    "                      x,                         # model input (or a tuple for multiple inputs)\n",
    "                      \"../cnn_baseline.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                      export_params=False,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=10,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=False,  # whether to execute constant folding for optimization\n",
    "                      input_names = ['input_images'],   # the model's input names\n",
    "                      output_names = ['output_prob'], # the model's output names\n",
    "                      dynamic_axes={'input_images' : {0 : 'batch_size'},    # variable length axes\n",
    "                                     'output_prob' : {0 : 'batch_size'}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, net, loss_fn, optimizer):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    current = 0\n",
    "    net.train()\n",
    "    \n",
    "    with tqdm(dataloader) as t:\n",
    "        for batch, (X, y) in enumerate(t):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = net(X)\n",
    "            loss = loss_fn(y_pred, y.long())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = (len(X) * loss.item() + running_loss * current) / (len(X) + current)\n",
    "            current += len(X)\n",
    "            t.set_postfix({'running_loss':running_loss})\n",
    "    \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop(dataloader, net, loss_fn):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    current = 0\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(dataloader) as t:\n",
    "            for batch, (X, y) in enumerate(t):\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                y_pred = net(X)\n",
    "                loss = loss_fn(y_pred, y.long())\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                running_loss = (len(X) * running_loss + loss.item() * current) / (len(X) + current)\n",
    "                current += len(X)\n",
    "            \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.load('/home/clidg/proj_2/pt/baseline_epoch_10_train_0.6865865240322523_eval_0.686580_.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检测到 1 个GPU\n",
      "只有一个GPU可用，不使用DataParallel\n"
     ]
    }
   ],
   "source": [
    "# 检查GPU可用性并设置DataParallel\n",
    "use_gpu = True\n",
    "if use_gpu:\n",
    "    # 检查CUDA是否可用\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"警告: CUDA不可用，将使用CPU\")\n",
    "        use_gpu = False\n",
    "        device = 'cpu'\n",
    "        net = net.to(device)\n",
    "    else:\n",
    "        # 检查可用GPU数量\n",
    "        available_gpus = torch.cuda.device_count()\n",
    "        print(f\"检测到 {available_gpus} 个GPU\")\n",
    "        \n",
    "        if available_gpus == 0:\n",
    "            print(\"警告: 没有可用的GPU，将使用CPU\")\n",
    "            use_gpu = False\n",
    "            device = 'cpu'\n",
    "            net = net.to(device)\n",
    "        elif available_gpus == 1:\n",
    "            print(\"只有一个GPU可用，不使用DataParallel\")\n",
    "            net = net.to(device)\n",
    "        else:\n",
    "            print(f\"使用DataParallel，GPU数量: {available_gpus}\")\n",
    "            net = net.to(device)\n",
    "            net = nn.DataParallel(net)\n",
    "elif use_gpu:\n",
    "    net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-5)\n",
    "\n",
    "start_epoch = 0\n",
    "min_val_loss = 1e9\n",
    "last_min_ind = -1\n",
    "early_stopping_epoch = 5\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:26<00:00,  3.15it/s, running_loss=1.18]\n",
      "100%|██████████| 18/18 [00:03<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:24<00:00,  3.40it/s, running_loss=1.09]\n",
      "100%|██████████| 18/18 [00:03<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:24<00:00,  3.35it/s, running_loss=1.02]\n",
      "100%|██████████| 18/18 [00:03<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:25<00:00,  3.24it/s, running_loss=0.989]\n",
      "100%|██████████| 18/18 [00:03<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:25<00:00,  3.23it/s, running_loss=0.929]\n",
      "100%|██████████| 18/18 [00:03<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:25<00:00,  3.22it/s, running_loss=0.906]\n",
      "100%|██████████| 18/18 [00:03<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:25<00:00,  3.26it/s, running_loss=0.861]\n",
      "100%|██████████| 18/18 [00:03<00:00,  4.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:25<00:00,  3.25it/s, running_loss=0.836]\n",
      "100%|██████████| 18/18 [00:03<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:25<00:00,  3.25it/s, running_loss=0.82] \n",
      "100%|██████████| 18/18 [00:03<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:25<00:00,  3.22it/s, running_loss=0.774]\n",
      "100%|██████████| 18/18 [00:03<00:00,  4.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:25<00:00,  3.25it/s, running_loss=0.752]\n",
      "100%|██████████| 18/18 [00:03<00:00,  4.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:25<00:00,  3.23it/s, running_loss=0.757]\n",
      "100%|██████████| 18/18 [00:03<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:25<00:00,  3.25it/s, running_loss=0.717]\n",
      "100%|██████████| 18/18 [00:03<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:25<00:00,  3.24it/s, running_loss=0.691]\n",
      "100%|██████████| 18/18 [00:03<00:00,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Best epoch: 8, val_loss: 0.6811516505452196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "os.mkdir('..\\\\pt'+os.sep+start_time)\n",
    "epochs = 100\n",
    "for t in range(start_epoch, epochs):\n",
    "    print(f\"Epoch {t}\\n-------------------------------\")\n",
    "    time.sleep(0.2)\n",
    "    train_loss = train_loop(train_dataloader, net, loss_fn, optimizer)\n",
    "    val_loss = val_loop(val_dataloader, net, loss_fn)\n",
    "    tb.add_histogram(\"train_loss\", train_loss, t)\n",
    "    torch.save(net, '../pt'+os.sep+start_time+os.sep+'baseline_epoch_{}_train_{:5f}_val_{:5f}.pt'.format(t, train_loss, val_loss)) \n",
    "    if val_loss < min_val_loss:\n",
    "        last_min_ind = t\n",
    "        min_val_loss = val_loss\n",
    "    elif t - last_min_ind >= early_stopping_epoch:\n",
    "        break\n",
    "\n",
    "print('Done!')\n",
    "print('Best epoch: {}, val_loss: {}'.format(last_min_ind, min_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
